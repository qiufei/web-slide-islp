---
title: "Statistical Learning: An Introduction"
---

## Welcome

::: {.r-fit-text}
:::: {.callout-note}
<span style="color:#2E86C1;">**Welcome to Statistical Learning!**</span> ðŸš€
::::
:::

This chapter provides a gentle introduction to the exciting world of statistical learning, a powerful toolkit for understanding data. We will explore the core concepts, see real-world examples, and start our journey toward building predictive models.

## What is Statistical Learning?

Statistical learning refers to a vast set of tools for *understanding data*. It's about extracting meaningful insights and making predictions from data. These tools can be broadly classified into two categories:  **Supervised** and **Unsupervised Learning**.

Think of it like using data to teach a computer to:

*   **Predict:**  Estimate a future outcome (e.g., will a customer click on an ad?).
*   **Infer:**  Understand relationships between variables (e.g., what factors influence house prices?).
*   **Discover:**  Find hidden patterns and structures (e.g., what groups of customers have similar buying habits?).

## Supervised Learning

**Supervised Learning:**

-   Building a model to *predict* or *estimate* an output based on one or more inputs (also known as predictors, features, or independent variables).
-   Think of it like teaching a computer to learn from examples where you provide both the questions (inputs) and the answers (outputs).  The algorithm learns the relationship between them.
-   **Example:** Predicting a house price based on its size, location, and number of bedrooms. We *know* the house prices (the "answers") for our training data.

## Unsupervised Learning

**Unsupervised Learning:**

-   Discovering relationships and structure in data *without* a predefined output variable. There's no "answer key."
-   Here, you're letting the computer explore the data and find patterns on its own.  The algorithm identifies groupings or patterns without being told what to look for.
-   **Example:** Grouping customers into different segments based on their purchasing behavior, without knowing in advance what those segments should be. We don't have pre-labeled groups.

## Supervised vs. Unsupervised: A Visual Analogy

Imagine you have a basket of fruits ðŸŽðŸŒðŸŠ.

-   **Supervised Learning:** You tell a child, "This is an apple, this is a banana, this is an orange."  Then you show them a new fruit and ask, "What is this?" You're providing *labeled* examples. The child learns to *classify* the fruits based on your labels.

## Supervised vs. Unsupervised: A Visual Analogy (Cont.)

-   **Unsupervised Learning:** You give the child the basket and say, "Sort these fruits into groups however you think is best." The child might group them by color, shape, or size, discovering inherent patterns *without* being told what to look for. The child *discovers* the categories.

## Data Mining, Machine Learning, and Statistical Learning

These terms are often used interchangeably, but there are subtle differences. This diagram helps visualize their relationships:

```{mermaid}
graph LR
    A[Data Mining] --> C(Common Ground)
    B[Machine Learning] --> C
    D[Statistical Learning] --> C
    C --> E[Insights & Predictions]
```

## Data Mining, Machine Learning, and Statistical Learning (Cont.)

-   **Data Mining:** Focuses on discovering patterns and extracting knowledge from *large* datasets, often using techniques from database management and computer science. Think "big data" and finding hidden patterns.  It's often about exploratory analysis in very large datasets.

-   **Machine Learning:** Primarily concerned with building algorithms that can *learn from and make predictions on data*. Emphasizes predictive accuracy and computational efficiency. The focus is on the algorithm *learning* to make good predictions. It's more focused on the *algorithms* themselves and their performance.

## Data Mining, Machine Learning, and Statistical Learning (Cont.)

-   **Statistical Learning:** A subfield of statistics that emphasizes *model interpretability and understanding the uncertainty* associated with predictions. Provides a rigorous statistical framework for machine learning. It combines statistical rigor with machine learning techniques. We want to *understand* why the model makes the predictions it does, and how confident we are in those predictions.

## Real-World Applications

Let's explore some real-world data sets that we will use throughout the course:

1.  **Wage Data:** Analyzing factors that influence a person's wage. (Supervised - Regression)
2.  **Stock Market Data:** Predicting stock market movements. (Supervised - Classification)
3.  **Gene Expression Data:** Identifying groups of genes with similar expression patterns. (Unsupervised - Clustering)

## Wage Data: Understanding Income

We want to understand how a person's *wage* is related to their:

-   **Age**
-   **Education**
-   **Year** (calendar year)

:::: {.callout-note}
The goal is to build a model that can predict a person's wage based on these factors. This is a *supervised learning* problem because we have wage data (the "output"). Specifically, it's a *regression* problem because the output (wage) is a continuous variable.
::::

## Wage Data: Wage vs. Age

![Wage as a function of age](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

## Wage Data: Wage vs. Age (Analysis - 1)

![Wage as a function of age](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

-  **Left Panel:** This scatterplot shows individual wages plotted against age. Each point represents a person.

## Wage Data: Wage vs. Age (Analysis - 2)

![Wage as a function of age](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

- The blue line represents the *average* wage for a given age.

## Wage Data: Wage vs. Age (Analysis - 3)

![Wage as a function of age](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

-  **Trend:** Wage generally *increases* with age until around 60, then *decreases*. This suggests a *non-linear* relationship. It's not a straight line!

## Wage Data: Wage vs. Age (Analysis - 4)

![Wage as a function of age](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

-  **Variability:** There's significant spread around the average, meaning age alone isn't a perfect predictor. Many other factors influence wage.

## Wage Data: Wage vs. Year

![Wage as a function of year](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

## Wage Data: Wage vs. Year (Analysis - 1)

![Wage as a function of year](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

-  **Center Panel:** Shows wage versus year. Each point represents a person.

## Wage Data: Wage vs. Year (Analysis - 2)

![Wage as a function of year](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

- the line shows the trend.

## Wage Data: Wage vs. Year (Analysis - 3)

![Wage as a function of year](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

-  **Observation:** There's a gradual *increase* in average wage over time (2003-2009). This could be due to inflation, economic growth, or other factors.

## Wage Data: Wage vs. Education

![Wage as a function of education](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

## Wage Data: Wage vs. Education (Analysis - 1)

![Wage as a function of education](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

- **Right Panel:** Boxplots of wage for different education levels (1 = lowest, 5 = highest).

## Wage Data: Wage vs. Education (Analysis - 2)

![Wage as a function of education](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

- Boxplots show the distribution of wages within each education group. The box represents the middle 50% of the data, the line in the box is the median, and the "whiskers" extend to the most extreme data points within 1.5 times the interquartile range (IQR) from the box. Outliers are shown as individual points.

## Wage Data: Wage vs. Education (Analysis - 3)

![Wage as a function of education](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

- **Observation:** Higher education generally leads to *higher* wages. The boxes (representing the middle 50% of wages) are generally higher for higher education levels.

## Wage Data: Wage vs. Education (Analysis - 4)

![Wage as a function of education](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_1.svg)

- **Conclusion:** Combining age, year, and education will likely provide the *most accurate* wage prediction. We need to consider *multiple* factors.

## Stock Market Data: Predicting Direction

-   **Goal:** Predict whether the S&P 500 stock index will *increase* or *decrease* on a given day.
-   **Input:** Percentage changes in the index over the *previous 5 days*.
-   **Output:** Categorical (qualitative) â€“ either "Up" or "Down". This is a *classification* problem (predicting a category, not a number).

## Stock Market Data: Previous Day's Change

![Boxplots of previous day's change](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

## Stock Market Data: Previous Day's Change (Analysis - 1)

![Boxplots of previous day's change](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

-   **Left Panel:** Boxplots show the distribution of the *previous day's* percentage change.

## Stock Market Data: Previous Day's Change (Analysis - 2)

![Boxplots of previous day's change](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

- The boxplots are separated by whether the market went "Up" or "Down" *today*.

## Stock Market Data: Previous Day's Change (Analysis - 3)

![Boxplots of previous day's change](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

-  **Observation:** The two boxplots are very *similar*. This means the distributions of yesterday's returns are almost the same whether the market goes up or down today.

## Stock Market Data: Previous Day's Change (Analysis - 4)

![Boxplots of previous day's change](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

- **Conclusion:** This suggests that yesterday's performance is *not* a strong predictor of today's direction.

## Stock Market Data: Two Day's Previous

![Boxplots of two day's previous](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

## Stock Market Data: Two Day's Previous (Analysis)
![Boxplots of two day's previous](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

-  **Center Panel:** Boxplots show the distribution of the *2 day's previous* percentage change, separated by whether the market went "Up" or "Down" *today*.
-  **Observation:** The two boxplots are very *similar*.

## Stock Market Data: Three Day's Previous

![Boxplots of three day's previous](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

## Stock Market Data: Three Day's Previous (Analysis)
![Boxplots of three day's previous](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_2.svg)

-  **Right Panel:** Boxplots show the distribution of the *3 day's previous* percentage change, separated by whether the market went "Up" or "Down" *today*.
-  **Observation:** The two boxplots are very *similar*.

## Stock Market Data: Predicting with QDA

![Quadratic Discriminant Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_3.svg)

## Stock Market Data: Predicting with QDA (Analysis - 1)

![Quadratic Discriminant Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_3.svg)

- A statistical learning method called *quadratic discriminant analysis (QDA)* was used to predict market direction. QDA is a classification method.  It assumes that the data within each class ("Up" or "Down") follows a Gaussian (normal) distribution, but with different covariance matrices for each class.

## Stock Market Data: Predicting with QDA (Analysis - 2)

![Quadratic Discriminant Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_3.svg)

- **Result:** The model correctly predicted the direction about 60% of the time. This is better than random guessing (50%), but still far from perfect. It suggests weak trends *might* exist, but predicting the stock market is *hard*!

## Gene Expression Data: Clustering

-   **Goal:** Identify *groups* (clusters) of cancer cell lines based on their gene expression measurements. We want to see if cell lines naturally group together based on how their genes are expressed.
-   **Input:** 6,830 gene expression measurements for each of 64 cancer cell lines. Each measurement represents the activity level of a gene.
-   **Output:** *None*. This is an *unsupervised learning* problem (specifically, a *clustering* problem). We don't have pre-defined groups; we want to *discover* them.

## Gene Expression Data: Principal Components

![Principal Components Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_4.svg)

## Gene Expression Data: Principal Components (Analysis - 1)

![Principal Components Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_4.svg)

- **Challenge:** Visualizing 6,830 dimensions is impossible! We can't directly "look" at the data.

## Gene Expression Data: Principal Components (Analysis - 2)

![Principal Components Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_4.svg)

- **Solution:** *Principal Component Analysis (PCA)* reduces the data to two dimensions (Z1 and Z2) that capture the most important information.  PCA finds the directions of greatest variation in the data. These directions are called *principal components*.

## Gene Expression Data: Principal Components (Analysis - 3)

![Principal Components Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_4.svg)

-   **Left Panel:** Each point represents a cell line, colored by a *suggested* cluster. At least four groups seem clear. This shows the result of the *unsupervised* clustering.  A clustering algorithm (like k-means) was likely applied to the data *after* PCA was used to reduce the dimensionality.

## Gene Expression Data: Principal Components (Analysis - 4)

![Principal Components Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_4.svg)

-   **Right Panel:** Same plot as the left panel (using the same PCA dimensions), but points are colored by the *actual* cancer type (14 types).  This is the "ground truth" that we *didn't* use for clustering.

## Gene Expression Data: Principal Components (Analysis - 5)

![Principal Components Analysis](https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F1_4.svg)

-   **Observation:** Cell lines with the same cancer type tend to cluster together, validating the unsupervised clustering. This means that even though we didn't *tell* the algorithm the cancer types, it was able to *discover* them (to some extent) from the gene expression data. This is the power of unsupervised learning!

## A Brief History of Statistical Learning

-   **Early Beginnings (19th Century):**  *Least squares* (linear regression) was developed by Legendre and Gauss. This is the foundation of many statistical learning methods. The goal is to find the line that minimizes the sum of squared differences between observed and predicted values.

-   **Mid-20th Century (1930s-1970s):** *Linear discriminant analysis* (LDA) was developed by Fisher(1936). *Logistic regression* was developed. These expanded the toolkit for classification and modeling different types of data. *Generalized linear models* (GLMs) were introduced, providing a unified framework for linear regression, logistic regression, and other models.

## A Brief History of Statistical Learning (Cont.)

-   **Computational Revolution (1980s onwards):** Non-linear methods become feasible (e.g., *trees*, *generalized additive models*). *Neural Networks* and *Support Vector Machines* were proposed. Computers became powerful enough to handle more complex calculations.

-   **Modern Era:** Statistical learning emerges as a distinct field, fueled by powerful software (like R and Python) and increasing data availability. The combination of data, algorithms, and computing power drives the field forward.

## Notation

It's important to understand the notation we'll use throughout the course:

-   **n:** Number of *observations* (data points). Think of this as the number of rows in your data table.  Each observation is a single instance of what you're studying (e.g., a person, a day, a cell line).

-   **p:** Number of *variables* (features, predictors). Think of this as the number of columns in your data table *excluding* the outcome variable (if there is one). Each variable is a characteristic you're measuring (e.g., age, education, stock price change).

## Notation (Cont.)

-   **x<sub>ij</sub>:** Value of the *j*th variable for the *i*th observation. This is a specific entry in your data table.  For example, x<sub>35</sub> would be the value of the 5th variable for the 3rd observation.

-   **X:** A matrix (n x p) representing the data. Think of it as a spreadsheet where rows are observations and columns are variables.

-    **y<sub>i</sub>:** the i<sup>th</sup> observation of the variable on which we wish to make predictions

## Notation (Cont.)

-   **Bold lowercase (e.g., a):** A vector of length *n*. This typically represents all the values of a single variable across all observations. For example, **y** might represent a vector of all the wages in the Wage dataset.

-   **Normal lowercase (e.g., a):** A scalar (single number) or a vector *not* of length *n*.

-   **Bold capitals (e.g., A):** A matrix.

## Notation: Example (Wage Data)

Let's apply the notation to the Wage data example:

-   n = 3000 (3000 people - our observations)
-   p = 11 (variables like year, age, education, etc. - our predictors)
-   x<sub>23</sub> would be the value of the 3rd variable (e.g., education) for the 2nd person.
-   **X** is a 3000 x 11 matrix (our data table).
-   y<sub>1</sub>: the first person's wage.

## Summary

-   Statistical learning provides tools to understand data, both with (supervised) and without (unsupervised) a specific outcome to predict.
-   Supervised learning aims to predict an output, while unsupervised learning explores data structure.
-   Data mining, machine learning, and statistical learning are related but have different emphases.
-   Real-world applications include predicting wages, stock market movements, and clustering gene expression data.
-   Understanding notation is crucial for following the rest of the course.

## Thoughts and Discussion

-   Can you think of other examples of supervised and unsupervised learning problems in your field of interest?
-   Why is it important to understand the *limitations* of statistical learning models, even when they achieve good predictive accuracy? (Hint: Consider issues like overfitting, bias, and the fact that correlation doesn't imply causation.)
-   What are the potential ethical implications of using statistical learning models in areas like hiring, loan applications, or criminal justice? (Hint: Consider issues like fairness, transparency, and accountability.)
-   How do you imagine the combination of increasing data availability, more powerful hardware, and user-friendly software will further transform the field of statistical learning, making more sophisticated machine learning available to even more researchers?

