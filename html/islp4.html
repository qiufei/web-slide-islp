<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>islp4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../https://assets.qiufei.site/personal/profile.jpg" rel="icon" type="image/jpeg">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ea72dc5fed832574809a9c94082fbbb.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-681fbf911679f9b3dbf9743eb275ba49.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-7e49aeac8059a213a463aa1a739e8272.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://qiufei.github.io"> 
<span class="menu-text">È¶ñÈ°µ</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://qiufei.github.io/web-slide-r"> 
<span class="menu-text">RËØæ‰ª∂</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://qiufei.github.io/web-slide-marketing"> 
<span class="menu-text">Ëê•ÈîÄËØæ‰ª∂</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="introduction-to-classification" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-classification">Introduction to Classification</h2>
<div class="incremental">
<ul class="incremental">
<li>So far, we‚Äôve focused on <strong>regression</strong> problems, where the response variable is <em>quantitative</em>.</li>
<li>Now, we shift gears to <strong>classification</strong> problems, where the response variable is <em>qualitative</em> (categorical).</li>
<li><strong>Goal:</strong> To predict a qualitative response ‚Äì that is, to classify an observation into a category or class.</li>
<li>Examples:
<ul class="incremental">
<li>Predicting whether a patient has a specific disease (yes/no).</li>
<li>Classifying an email as spam or not spam.</li>
<li>Determining whether a credit card transaction is fraudulent.</li>
</ul></li>
</ul>
</div>
</section>
<section id="what-is-classification" class="level2">
<h2 class="anchored" data-anchor-id="what-is-classification">What is Classification?</h2>
<ul>
<li><strong>Classification</strong> involves assigning an observation to a category, or class.</li>
<li>It‚Äôs like sorting things into different boxes. üì¶</li>
<li>Many methods first predict the <em>probability</em> of belonging to each category, and classify based on those probabilities.</li>
</ul>
</section>
<section id="classification-vs.-regression" class="level2">
<h2 class="anchored" data-anchor-id="classification-vs.-regression">Classification vs.&nbsp;Regression</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Regression</th>
<th>Classification</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Response Variable</td>
<td>Quantitative</td>
<td>Qualitative</td>
</tr>
<tr class="even">
<td>Goal</td>
<td>Predict a numerical value</td>
<td>Predict a category</td>
</tr>
<tr class="odd">
<td>Example</td>
<td>Predict house price</td>
<td>Predict disease presence (yes/no)</td>
</tr>
</tbody>
</table>
</section>
<section id="why-not-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="why-not-linear-regression">Why Not Linear Regression?</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Text material pointed out linear regression is not appropriate in the case of a qualitative response.</li>
<li>Suppose there are three possible diagnoses: <em>stroke</em>, <em>drug overdose</em>, and <em>epileptic seizure</em>.</li>
<li>We <em>could</em> try coding them numerically (e.g., 1=stroke, 2=drug overdose, 3=epileptic seizure).</li>
</ul>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2Fcoding.png" class="img-fluid figure-img"></p>
<figcaption>Medical conditions coding</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="incremental">
<ul class="incremental">
<li>But this imposes an <em>order</em> and <em>equal differences</em> that may not make sense!</li>
<li>Different codings would give completely different models and predictions!</li>
<li>For <em>binary</em> (two-level) responses, linear regression <em>can</em> work (0/1 coding), but probabilities might fall outside [0,1]. Better options exist!</li>
</ul>
</div>
</section>
<section id="example-the-default-data" class="level2">
<h2 class="anchored" data-anchor-id="example-the-default-data">Example: The Default Data</h2>
<ul>
<li>We‚Äôll use a simulated dataset called ‚ÄúDefault‚Äù.</li>
<li>Goal: Predict whether an individual will default on their credit card payment.</li>
<li>Predictors:
<ul>
<li>Annual income.</li>
<li>Monthly credit card balance.</li>
</ul></li>
<li>Response: <code>default</code> (Yes/No)</li>
</ul>
</section>
<section id="visualizing-the-default-data" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-the-default-data">Visualizing the Default Data</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_1.svg" class="img-fluid figure-img" width="800"></p>
<figcaption>The Default data set</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><strong>Left:</strong> Scatterplot of income and balance, color-coded by default status (orange = defaulted, blue = did not default).</li>
<li><strong>Center:</strong> Boxplots of balance, separated by default status. Defaulters tend to have higher balances.</li>
<li><strong>Right:</strong> Boxplots of income, separated by default status. The relationship is less clear here.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Higher credit card balances seem associated with a higher probability of default.</p>
</div>
</div>
</div>
</section>
<section id="logistic-regression-the-core-idea" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-the-core-idea">Logistic Regression: The Core Idea</h2>
<ul>
<li>Instead of modeling the <em>response</em> directly, logistic regression models the <em>probability</em> that Y belongs to a particular category.</li>
<li>For the Default data, we model: Pr(default = Yes | balance, income)</li>
<li>This probability will always be between 0 and 1. üëç</li>
<li>Once we have the probability, we can classify (e.g., predict ‚Äúdefault=Yes‚Äù if the probability is &gt; 0.5).</li>
</ul>
</section>
<section id="the-logistic-model" class="level2">
<h2 class="anchored" data-anchor-id="the-logistic-model">The Logistic Model</h2>
<ul>
<li>We need a function that outputs values between 0 and 1, for any input. The <strong>logistic function</strong> does this!</li>
</ul>
<p><span class="math display">\[
p(X) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}
\]</span></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><em>p(X)</em>: Probability of the event (e.g., default) given predictor(s) <em>X</em>.</li>
<li>Œ≤‚ÇÄ and Œ≤‚ÇÅ: Coefficients estimated from the data.</li>
<li><em>e</em>: The base of the natural logarithm (approximately 2.718).</li>
</ul>
</div>
</div>
</div>
<ul>
<li>This produces an S-shaped curve.</li>
</ul>
</section>
<section id="linear-vs.-logistic-regression-on-default-data" class="level2">
<h2 class="anchored" data-anchor-id="linear-vs.-logistic-regression-on-default-data">Linear vs.&nbsp;Logistic Regression on Default Data</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_2.svg" class="img-fluid figure-img" width="800"></p>
<figcaption>Classification using the Default data</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><strong>Left:</strong> Linear regression. Notice the negative probabilities and probabilities &gt; 1! üôÅ</li>
<li><strong>Right:</strong> Logistic regression. Probabilities are always between 0 and 1. üôÇ</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Logistic regression provides a more sensible fit for binary outcomes.</p>
</div>
</div>
</div>
</section>
<section id="the-logistic-model-continued" class="level2">
<h2 class="anchored" data-anchor-id="the-logistic-model-continued">The Logistic Model (Continued)</h2>
<ul>
<li>A little algebra reveals a connection to <em>odds</em>:</li>
</ul>
<p><span class="math display">\[
\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1X}
\]</span></p>
<ul>
<li><p>The left side is the <strong>odds</strong>, which can range from 0 to ‚àû.</p></li>
<li><p>Taking the logarithm of both sides:</p></li>
</ul>
<p><span class="math display">\[
\log\left(\frac{p(X)}{1 - p(X)}\right) = \beta_0 + \beta_1X
\]</span></p>
<ul>
<li>The left side is the <strong>log-odds</strong> or <strong>logit</strong>. This is <em>linear</em> in X!</li>
</ul>
</section>
<section id="interpreting-the-coefficients" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-coefficients">Interpreting the Coefficients</h2>
<ul>
<li>In linear regression, Œ≤‚ÇÅ is the <em>average change in Y</em> for a one-unit increase in X.</li>
<li>In logistic regression, Œ≤‚ÇÅ is the <em>change in the log-odds</em> for a one-unit increase in X.</li>
<li>Equivalently, a one-unit increase in X <em>multiplies the odds</em> by e<sup>Œ≤‚ÇÅ</sup>.</li>
<li>The <em>amount</em> p(X) changes depends on the <em>current value</em> of X, because the relationship is non-linear.</li>
</ul>
</section>
<section id="estimating-the-coefficients" class="level2">
<h2 class="anchored" data-anchor-id="estimating-the-coefficients">Estimating the Coefficients</h2>
<ul>
<li>We use <strong>maximum likelihood estimation (MLE)</strong>.<br>
</li>
<li>The goal is to find the coefficients (Œ≤‚ÇÄ, Œ≤‚ÇÅ, etc.) that make the <em>observed data</em> most likely.</li>
<li>The likelihood function for logistic regression:</li>
</ul>
<p><span class="math display">\[
l(\beta_0, \beta_1) = \prod_{i:y_i=1} p(x_i) \prod_{i':y_{i'}=0} (1 - p(x_{i'}))
\]</span></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>We multiply the probabilities of observing each data point, given the coefficients.</li>
<li>For defaulters (y·µ¢=1), we use p(x·µ¢). For non-defaulters (y·µ¢‚Äô=0), we use 1-p(x·µ¢‚Äô).</li>
</ul>
</div>
</div>
</div>
<ul>
<li>Software (like R) handles the maximization for us.</li>
</ul>
</section>
<section id="making-predictions" class="level2">
<h2 class="anchored" data-anchor-id="making-predictions">Making Predictions</h2>
<ul>
<li><p>Once we have the estimated coefficients, we can predict the probability of default for <em>any</em> given values of balance and income.</p></li>
<li><p>Example (using coefficients from Table 4.1):</p>
<ul>
<li>balance = $1,000: p(X) ‚âà 0.00576 (less than 1% chance of default)</li>
<li>balance = $2,000: p(X) ‚âà 0.586 (58.6% chance of default)</li>
</ul></li>
<li><p>We can classify based on a threshold (e.g., classify as ‚Äúdefault‚Äù if p(X) &gt; 0.5).</p></li>
</ul>
</section>
<section id="multiple-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="multiple-logistic-regression">Multiple Logistic Regression</h2>
<ul>
<li>Just like with linear regression, we can include <em>multiple predictors</em>:</li>
</ul>
<p><span class="math display">\[
\log\left(\frac{p(X)}{1 - p(X)}\right) = \beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_pX_p
\]</span> <span class="math display">\[
p(X) = \frac{e^{\beta_0 + \beta_1X_1 + \dots + \beta_pX_p}}{1 + e^{\beta_0 + \beta_1X_1 + \dots + \beta_pX_p}}
\]</span> - We estimate the coefficients using MLE. - Interpretation: Œ≤‚±º represents the change in log-odds for a one-unit increase in X‚±º, <em>holding all other predictors constant</em>.</p>
</section>
<section id="example-multiple-logistic-regression-on-default-data" class="level2">
<h2 class="anchored" data-anchor-id="example-multiple-logistic-regression-on-default-data">Example: Multiple Logistic Regression on Default Data</h2>
<ul>
<li>Predictors: balance, income, student (dummy variable: 1 if student, 0 if not).</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 20%">
<col style="width: 15%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Coefficient</th>
<th style="text-align: left;">Std. error</th>
<th style="text-align: left;">z-statistic</th>
<th style="text-align: left;">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Intercept</td>
<td style="text-align: left;">-10.8690</td>
<td style="text-align: left;">0.4923</td>
<td style="text-align: left;">-22.08</td>
<td style="text-align: left;">&lt; 0.0001</td>
</tr>
<tr class="even">
<td style="text-align: left;">balance</td>
<td style="text-align: left;">0.0057</td>
<td style="text-align: left;">0.0002</td>
<td style="text-align: left;">24.74</td>
<td style="text-align: left;">&lt; 0.0001</td>
</tr>
<tr class="odd">
<td style="text-align: left;">income</td>
<td style="text-align: left;">0.0030</td>
<td style="text-align: left;">0.0082</td>
<td style="text-align: left;">0.37</td>
<td style="text-align: left;">0.7115</td>
</tr>
<tr class="even">
<td style="text-align: left;">student[Yes]</td>
<td style="text-align: left;">-0.6468</td>
<td style="text-align: left;">0.2362</td>
<td style="text-align: left;">-2.74</td>
<td style="text-align: left;">0.0062</td>
</tr>
</tbody>
</table>
<ul>
<li><em>Surprising</em> result: The coefficient for <code>student</code> is <em>negative</em>! This suggests students are <em>less</em> likely to default, holding balance and income constant.</li>
</ul>
</section>
<section id="confounding" class="level2">
<h2 class="anchored" data-anchor-id="confounding">Confounding</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_3.svg" class="img-fluid figure-img"></p>
<figcaption>Confounding in the Default data.</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><strong>Left:</strong> Default rates for students (orange) and non-students (blue) as a function of balance. Solid lines: default rate at each balance. Dashed lines: <em>overall</em> default rate.</li>
<li><strong>Right:</strong> Boxplots of balance for students and non-students.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>Students have <em>higher</em> overall default rates (dashed lines), but <em>lower</em> default rates at each balance level (solid lines).</li>
<li>Reason: <code>student</code> and <code>balance</code> are <em>correlated</em>. Students tend to have higher balances, which are associated with higher default rates.</li>
<li>This is <strong>confounding</strong>: The effect of one predictor is mixed up with the effect of another.</li>
</ul>
</section>
<section id="multinomial-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="multinomial-logistic-regression">Multinomial Logistic Regression</h2>
<ul>
<li>What if the response has <em>more than two</em> categories? (e.g., medical diagnosis: stroke, drug overdose, epileptic seizure)</li>
<li><strong>Multinomial logistic regression</strong> extends the two-class case.</li>
<li>We choose a <em>baseline</em> category (e.g., the Kth category).</li>
<li>We model the log-odds of each category <em>relative to the baseline</em>:</li>
</ul>
<p><span class="math display">\[
\log\left(\frac{\Pr(Y = k|X = x)}{\Pr(Y = K|X = x)}\right) = \beta_{k0} + \beta_{k1}x_1 + \dots + \beta_{kp}x_p
\]</span></p>
<ul>
<li>There are K-1 sets of coefficients.</li>
<li>The choice of baseline is arbitrary; the <em>predictions</em> will be the same regardless.</li>
</ul>
</section>
<section id="multinomial-logistic-regression-softmax-coding" class="level2">
<h2 class="anchored" data-anchor-id="multinomial-logistic-regression-softmax-coding">Multinomial Logistic Regression: Softmax Coding</h2>
<ul>
<li>An alternative, equivalent formulation is <strong>softmax coding</strong>.</li>
<li>Instead of a baseline, we treat all <em>K</em> classes symmetrically:</li>
</ul>
<p><span class="math display">\[
\Pr(Y = k|X = x) = \frac{e^{\beta_{k0} + \beta_{k1}x_1 + \dots + \beta_{kp}x_p}}{\sum_{l=1}^K e^{\beta_{l0} + \beta_{l1}x_1 + \dots + \beta_{lp}x_p}}
\]</span></p>
<ul>
<li>This is often used in machine learning.</li>
</ul>
</section>
<section id="generative-models-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="generative-models-for-classification">Generative Models for Classification</h2>
<ul>
<li>Logistic regression <em>directly</em> models Pr(Y = k | X = x).</li>
<li>Now we explore an <em>indirect</em> approach:
<ol type="1">
<li>Model the distribution of the predictors <em>X</em> separately in each response class (i.e., for each value of <em>Y</em>).</li>
<li>Use <strong>Bayes‚Äô theorem</strong> to ‚Äúflip‚Äù these around into estimates of Pr(Y = k | X = x).</li>
</ol></li>
<li>These are called <strong>generative models</strong> because they specify how the data is generated.</li>
</ul>
</section>
<section id="bayes-theorem-for-classification" class="level2">
<h2 class="anchored" data-anchor-id="bayes-theorem-for-classification">Bayes‚Äô Theorem for Classification</h2>
<ul>
<li>Let œÄ<sub>k</sub> be the <em>prior probability</em> that an observation comes from class <em>k</em>.</li>
<li>Let f<sub>k</sub>(X) = Pr(X | Y = k) be the <em>density function</em> of X for an observation from class <em>k</em>.</li>
<li><strong>Bayes‚Äô theorem</strong> states:</li>
</ul>
<p><span class="math display">\[
\Pr(Y = k|X = x) = \frac{\pi_k f_k(x)}{\sum_{l=1}^K \pi_l f_l(x)}
\]</span></p>
<ul>
<li>To use this, we need to estimate œÄ<sub>k</sub> and f<sub>k</sub>(x). Estimating œÄ<sub>k</sub> is usually easy (fraction of training observations in class k). Estimating f<sub>k</sub>(x) is harder.</li>
</ul>
</section>
<section id="why-bother-with-generative-models" class="level2">
<h2 class="anchored" data-anchor-id="why-bother-with-generative-models">Why Bother with Generative Models?</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p>If we already have logistic regression, why use this indirect approach?</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>When there is substantial separation between classes, logistic regression parameters can be unstable. Generative models may be better.</li>
<li>If the distribution of predictors is approximately normal within each class, and the sample size is small, generative models may be more accurate.</li>
<li>Generative models can be easily extended to more than two response classes.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="linear-discriminant-analysis-lda" class="level2">
<h2 class="anchored" data-anchor-id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h2>
<ul>
<li><strong>Assumptions:</strong>
<ul>
<li>f<sub>k</sub>(x) is <em>normal</em> (Gaussian).</li>
<li>We have a <em>common variance</em> across all K classes (œÉ¬≤).</li>
</ul></li>
<li>For a single predictor (p=1):</li>
</ul>
<p><span class="math display">\[
f_k(x) = \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{1}{2\sigma^2}(x - \mu_k)^2\right)
\]</span></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>Œº<sub>k</sub>: mean for class k</li>
<li>œÉ¬≤: common variance</li>
</ul>
</div>
</div>
</div>
</section>
<section id="lda-continued" class="level2">
<h2 class="anchored" data-anchor-id="lda-continued">LDA (Continued)</h2>
<ul>
<li>Plugging f<sub>k</sub>(x) into Bayes‚Äô theorem and simplifying, we classify an observation to the class for which this is largest:</li>
</ul>
<p><span class="math display">\[
\delta_k(x) = x \cdot \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + \log(\pi_k)
\]</span></p>
<ul>
<li>This is the <strong>discriminant function</strong>. It‚Äôs <em>linear</em> in x. That‚Äôs why it‚Äôs called <em>Linear</em> Discriminant Analysis!</li>
<li>In practice, we don‚Äôt know the true parameters (œÄ<sub>k</sub>, Œº<sub>k</sub>, œÉ¬≤). We <em>estimate</em> them from the training data.</li>
</ul>
</section>
<section id="lda-estimating-the-parameters" class="level2">
<h2 class="anchored" data-anchor-id="lda-estimating-the-parameters">LDA: Estimating the Parameters</h2>
<ul>
<li><p>ŒºÃÇ<sub>k</sub> = (1/n<sub>k</sub>) Œ£<sub>i:y·µ¢=k</sub> x·µ¢ (sample mean for class k)</p></li>
<li><p>œÉÃÇ¬≤ = (1/(n-K)) Œ£<sub>k=1</sub><sup>K</sup> Œ£<sub>i:y·µ¢=k</sub> (x·µ¢ - ŒºÃÇ<sub>k</sub>)¬≤ (pooled variance estimate)</p></li>
<li><p>œÄÃÇ<sub>k</sub> = n<sub>k</sub>/n (sample proportion for class k)</p></li>
<li><p>We plug these estimates into the discriminant function.</p></li>
</ul>
</section>
<section id="lda-example" class="level2">
<h2 class="anchored" data-anchor-id="lda-example">LDA: Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_4.svg" class="img-fluid figure-img"></p>
<figcaption>One-dimensional normal density functions and LDA decision boundary</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><strong>Left:</strong> Two normal density functions. Dashed line: Bayes decision boundary.</li>
<li><strong>Right:</strong> 20 observations from each class (histograms). Dashed line: Bayes boundary. Solid line: LDA boundary.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>LDA approximates the Bayes classifier.</li>
</ul>
</section>
<section id="lda-with-multiple-predictors-p-1" class="level2">
<h2 class="anchored" data-anchor-id="lda-with-multiple-predictors-p-1">LDA with Multiple Predictors (p &gt; 1)</h2>
<ul>
<li><p>We assume X = (X‚ÇÅ, X‚ÇÇ, ‚Ä¶, X<sub>p</sub>) follows a <em>multivariate Gaussian</em> distribution, with a class-specific mean vector and a <em>common covariance matrix</em>.</p></li>
<li><p>Multivariate Gaussian density:</p></li>
</ul>
<p><span class="math display">\[
f(x) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(x - \mu)^T\Sigma^{-1}(x - \mu)\right)
\]</span></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>Œº: mean vector</li>
<li>Œ£: covariance matrix</li>
<li>|Œ£|: determinant of Œ£</li>
</ul>
</div>
</div>
</div>
</section>
<section id="lda-with-multiple-predictors-continued" class="level2">
<h2 class="anchored" data-anchor-id="lda-with-multiple-predictors-continued">LDA with Multiple Predictors (Continued)</h2>
<ul>
<li>Plugging the multivariate Gaussian density into Bayes‚Äô theorem, we classify to the class for which this is largest:</li>
</ul>
<p><span class="math display">\[
\delta_k(x) = x^T \Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + \log \pi_k
\]</span></p>
<ul>
<li>Again, this is <em>linear</em> in x.</li>
<li>We estimate the parameters (Œº<sub>k</sub>, Œ£, œÄ<sub>k</sub>) from the training data.</li>
</ul>
</section>
<section id="lda-example-with-three-classes" class="level2">
<h2 class="anchored" data-anchor-id="lda-example-with-three-classes">LDA: Example with Three Classes</h2>
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_6.svg" class="img-fluid" alt="Multivariate Gaussian distribution with three classes, and LDA decision boundaries"> ::: {.callout-note appearance=‚Äúsimple‚Äù} - <strong>Left:</strong> Ellipses contain 95% of the probability for each class. Dashed lines: Bayes decision boundaries. - <strong>Right:</strong> 20 observations from each class. Solid lines: LDA decision boundaries. ::: - LDA approximates the Bayes decision boundaries.</p>
</section>
<section id="lda-on-the-default-data" class="level2">
<h2 class="anchored" data-anchor-id="lda-on-the-default-data">LDA on the Default Data</h2>
<ul>
<li>We can apply LDA to the Default data (predicting default based on balance and student status).</li>
<li>Training error rate: 2.75%. Sounds good, but‚Ä¶</li>
<li>Two problems:
<ol type="1">
<li>Training error rates are usually lower than <em>test error rates</em>.</li>
<li>Only 3.33% of individuals in the training data defaulted. A <em>useless</em> classifier that always predicts ‚Äúno default‚Äù would have a 3.33% error rate! (This is the <strong>null classifier</strong>.)</li>
</ol></li>
</ul>
</section>
<section id="confusion-matrix" class="level2">
<h2 class="anchored" data-anchor-id="confusion-matrix">Confusion Matrix</h2>
<ul>
<li>A <strong>confusion matrix</strong> shows the types of errors being made.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 35%">
<col style="width: 25%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Predicted No Default</th>
<th style="text-align: left;">Predicted Default</th>
<th style="text-align: left;">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Actual No Default</td>
<td style="text-align: left;">9644</td>
<td style="text-align: left;">23</td>
<td style="text-align: left;">9667</td>
</tr>
<tr class="even">
<td style="text-align: left;">Actual Default</td>
<td style="text-align: left;">252</td>
<td style="text-align: left;">81</td>
<td style="text-align: left;">333</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: left;">9896</td>
<td style="text-align: left;">104</td>
<td style="text-align: left;">10000</td>
</tr>
</tbody>
</table>
<ul>
<li>LDA misclassifies 252/333 = 75.7% of defaulters! (Low <strong>sensitivity</strong>.)</li>
<li>But it correctly classifies (1 - 23/9667) = 99.8% of non-defaulters. (High <strong>specificity</strong>.)</li>
</ul>
</section>
<section id="modifying-the-threshold" class="level2">
<h2 class="anchored" data-anchor-id="modifying-the-threshold">Modifying the Threshold</h2>
<ul>
<li>LDA (and the Bayes classifier) uses a threshold of 0.5 for the posterior probability of default.</li>
<li>If we <em>lower</em> the threshold (e.g., to 0.2), we can increase sensitivity (correctly identify more defaulters), but at the cost of decreased specificity (more false positives).</li>
<li>The best threshold depends on the <em>relative costs</em> of the two types of errors.</li>
</ul>
</section>
<section id="roc-curves" class="level2">
<h2 class="anchored" data-anchor-id="roc-curves">ROC Curves</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_7.svg" class="img-fluid figure-img"></p>
<figcaption>Error rates as a function of threshold</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>Shows various error rates as the threshold changes.</li>
<li>Black solid line: overall error rate</li>
<li>Blue dashed line: fraction of defaulters incorrectly classified</li>
<li>Orange dotted line: fraction of errors among non-defaulters</li>
</ul>
</div>
</div>
</div>
<ul>
<li>A <strong>Receiver Operating Characteristic (ROC) curve</strong> plots the <em>true positive rate</em> (sensitivity) versus the <em>false positive rate</em> (1 - specificity) for all possible thresholds.</li>
</ul>
</section>
<section id="roc-curve-continued" class="level2">
<h2 class="anchored" data-anchor-id="roc-curve-continued">ROC Curve (Continued)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_8.svg" class="img-fluid figure-img"></p>
<figcaption>ROC curve for LDA classifier on Default data</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>Ideal curve hugs the top left corner (high true positive rate, low false positive rate).</li>
<li>Dotted line: ‚Äúno information‚Äù classifier.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>The <strong>area under the curve (AUC)</strong> summarizes performance. AUC = 1 is perfect; AUC = 0.5 is no better than chance.</li>
</ul>
</section>
<section id="quadratic-discriminant-analysis-qda" class="level2">
<h2 class="anchored" data-anchor-id="quadratic-discriminant-analysis-qda">Quadratic Discriminant Analysis (QDA)</h2>
<ul>
<li><strong>QDA</strong> relaxes the assumption of a <em>common</em> covariance matrix.</li>
<li>Each class has its <em>own</em> covariance matrix, Œ£<sub>k</sub>.</li>
<li>The discriminant function becomes <em>quadratic</em> in x:</li>
</ul>
<p><span class="math display">\[
\delta_k(x) = -\frac{1}{2}x^T\Sigma_k^{-1}x + x^T\Sigma_k^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma_k^{-1}\mu_k - \frac{1}{2}\log|\Sigma_k| + \log \pi_k
\]</span></p>
<ul>
<li>We estimate the parameters (Œº<sub>k</sub>, Œ£<sub>k</sub>, œÄ<sub>k</sub>) from the training data.</li>
</ul>
</section>
<section id="lda-vs.-qda-bias-variance-trade-off" class="level2">
<h2 class="anchored" data-anchor-id="lda-vs.-qda-bias-variance-trade-off">LDA vs.&nbsp;QDA: Bias-Variance Trade-Off</h2>
<ul>
<li>QDA is more <em>flexible</em> than LDA (more parameters to estimate).</li>
<li>QDA has <em>higher variance</em> but potentially <em>lower bias</em>.</li>
<li>LDA tends to be better when there are <em>fewer</em> training observations (reducing variance is crucial).</li>
<li>QDA is recommended when the training set is <em>large</em>, or when the assumption of a common covariance matrix is clearly untenable.</li>
</ul>
</section>
<section id="lda-vs.-qda-example" class="level2">
<h2 class="anchored" data-anchor-id="lda-vs.-qda-example">LDA vs.&nbsp;QDA: Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_9.svg" class="img-fluid figure-img"></p>
<figcaption>LDA and QDA decision boundaries</figcaption>
</figure>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li><strong>Left:</strong> Classes have <em>common</em> correlation. Bayes boundary (dashed) is linear. LDA (black dotted) is better than QDA (green solid).</li>
<li><strong>Right:</strong> Classes have <em>different</em> correlations. Bayes boundary is quadratic. QDA is better than LDA.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="naive-bayes">Naive Bayes</h2>
<ul>
<li>Makes a <em>very</em> strong assumption: <strong>Within each class, the <em>p</em> predictors are independent.</strong></li>
<li>f<sub>k</sub>(x) = f<sub>k1</sub>(x‚ÇÅ) √ó f<sub>k2</sub>(x‚ÇÇ) √ó ‚Ä¶ √ó f<sub>kp</sub>(x<sub>p</sub>)
<ul>
<li>f<sub>kj</sub> is the density function of the jth predictor in class k.</li>
</ul></li>
<li>This simplifies things <em>a lot</em>! We only need to estimate <em>one-dimensional</em> densities.</li>
<li>We plug this into Bayes‚Äô theorem:</li>
</ul>
<p><span class="math display">\[
\Pr(Y = k|X = x) = \frac{\pi_k \times f_{k1}(x_1) \times f_{k2}(x_2) \times \dots \times f_{kp}(x_p)}{\sum_{l=1}^K \pi_l \times f_{l1}(x_1) \times f_{l2}(x_2) \times \dots \times f_{lp}(x_p)}
\]</span></p>
</section>
<section id="naive-bayes-estimating-the-one-dimensional-densities" class="level2">
<h2 class="anchored" data-anchor-id="naive-bayes-estimating-the-one-dimensional-densities">Naive Bayes: Estimating the One-Dimensional Densities</h2>
<ul>
<li>If X<sub>j</sub> is <em>quantitative</em>:
<ul>
<li>We can assume X<sub>j</sub> | Y = k ~ N(Œº<sub>jk</sub>, œÉ<sub>j</sub>¬≤) (Gaussian).</li>
<li>Or, we can use a non-parametric estimate (e.g., histogram, kernel density estimator).</li>
</ul></li>
<li>If X<sub>j</sub> is <em>qualitative</em>:
<ul>
<li>We can simply count the proportion of training observations for each level of the predictor within each class.</li>
</ul></li>
</ul>
</section>
<section id="naive-bayes-example" class="level2">
<h2 class="anchored" data-anchor-id="naive-bayes-example">Naive Bayes: Example</h2>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_10_1.svg" class="img-fluid figure-img"></p>
<figcaption>f11</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_10_2.svg" class="img-fluid figure-img"></p>
<figcaption>f12</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_10_3.svg" class="img-fluid figure-img"></p>
<figcaption>f13</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_10_4.svg" class="img-fluid figure-img"></p>
<figcaption>f21</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_10_5.svg" class="img-fluid figure-img"></p>
<figcaption>f22</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_10_6.svg" class="img-fluid figure-img"></p>
<figcaption>f23</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>Two classes (K=2), three predictors (p=3). First two predictors are quantitative, third is qualitative (three levels).</li>
<li>Estimated density functions f<sub>kj</sub> are shown.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>Naive Bayes often works surprisingly well, despite the strong independence assumption. It reduces variance, which can be beneficial.</li>
</ul>
</section>
<section id="comparison-of-classification-methods-an-analytical-perspective" class="level2">
<h2 class="anchored" data-anchor-id="comparison-of-classification-methods-an-analytical-perspective">Comparison of Classification Methods: An Analytical Perspective</h2>
<ul>
<li>Logistic regression, LDA, QDA, and naive Bayes can all be expressed in terms of maximizing Pr(Y = k | X = x).</li>
<li>Equivalently, we can maximize the log-odds relative to a baseline class (K):</li>
</ul>
<p><span class="math display">\[
\log\left(\frac{\Pr(Y = k|X = x)}{\Pr(Y = K|X = x)}\right)
\]</span></p>
<ul>
<li>The <em>form</em> of this log-odds expression differs for each method.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 89%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Log-Odds Form</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Logistic Regression</td>
<td style="text-align: left;">Œ≤<sub>k0</sub> + Œ£<sub>j=1</sub><sup>p</sup> Œ≤<sub>kj</sub>x<sub>j</sub> (linear)</td>
</tr>
<tr class="even">
<td style="text-align: left;">LDA</td>
<td style="text-align: left;">a<sub>k</sub> + Œ£<sub>j=1</sub><sup>p</sup> b<sub>kj</sub>x<sub>j</sub> (linear)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">QDA</td>
<td style="text-align: left;">a<sub>k</sub> + Œ£<sub>j=1</sub><sup>p</sup> b<sub>kj</sub>x<sub>j</sub> + Œ£<sub>j=1</sub><sup>p</sup> Œ£<sub>l=1</sub><sup>p</sup> c<sub>kj</sub><sub>l</sub>x<sub>j</sub>x<sub>l</sub> (quadratic)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Naive Bayes</td>
<td style="text-align: left;">a<sub>k</sub> + Œ£<sub>j=1</sub><sup>p</sup> g<sub>kj</sub>(x<sub>j</sub>) (additive, where g<sub>kj</sub> is a function of x<sub>j</sub>)</td>
</tr>
</tbody>
</table>
<ul>
<li>LDA is a special case of QDA.</li>
<li>Any classifier with a <em>linear</em> decision boundary is a special case of naive Bayes.</li>
<li>Logistic regression has the same <em>linear</em> form as LDA, but the coefficients are estimated differently.</li>
<li>None of the method dominate others universally.</li>
</ul>
</section>
<section id="a-comparison-of-classification-methodsan-empirical-comparison" class="level2">
<h2 class="anchored" data-anchor-id="a-comparison-of-classification-methodsan-empirical-comparison">A comparison of classification methodsÔºöAn empirical comparison</h2>
<ul>
<li>Test error rates of different methods are compared through six different scenarios.</li>
</ul>
<style>
.half-width {
  width: 50%;
  float: left;
}
</style>
<div>

</div>
<div class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="half-width quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_11.svg" class="img-fluid figure-img"></p>
<figcaption>FIGURE 4.11</figcaption>
</figure>
</div>
</div>
<div class="half-width quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://axwslyfy9krb.objectstorage.ap-singapore-1.oci.customer-oci.com/n/axwslyfy9krb/b/qiufei/o/textbook%2Fisl_figures%2F4_12.svg" class="img-fluid figure-img"></p>
<figcaption>FIGURE 4.12</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>Six different scenarios are involved, scenarios 1-3 Bayes decision boundaries are linear, and scenarios 4-6 Bayes decision boundaries are non-linear.</li>
<li>There were p=2 quantitative predictors in each of the six scenarios.</li>
<li>For each scenario, 100 random training data sets were generated.</li>
<li>Scenario 1 to Scenario 6 are described in the text material page 31 and page 32.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>When the true decision boundaries are <em>linear</em>, LDA and logistic regression perform well.</li>
<li>When boundaries are moderately non-linear, QDA or naive Bayes may be better.</li>
<li>For <em>very</em> complex boundaries, a non-parametric method like KNN can be superior, <em>but</em> the level of smoothness must be chosen carefully.</li>
</ul>
</section>
<section id="generalized-linear-models-glms" class="level2">
<h2 class="anchored" data-anchor-id="generalized-linear-models-glms">Generalized Linear Models (GLMs)</h2>
<ul>
<li>So far, the response Y is either quantitative(use least squares linear regression to predict) or qualitative(use classification methods).</li>
<li>But Y is neither qualitative nor quantitative is also possible, like the number of hourly users of a bike sharing program.</li>
<li>To predict the number of bike users, the least squares linear regression model shown defects(negative fitted values, variance increasing when mean number increasing, response not continuous-valued)</li>
<li>Poisson regression could provide a much more natural and elegant approach.</li>
</ul>
</section>
<section id="poisson-regression" class="level2">
<h2 class="anchored" data-anchor-id="poisson-regression">Poisson Regression</h2>
<ul>
<li>Suppose the random variable Y takes on nonnegative integer values and follows the Poisson distribution. The probability could be written as:</li>
</ul>
<p><span class="math display">\[
\Pr(Y = k) = \frac{e^{-\lambda}\lambda^k}{k!}  \quad \text{for } k = 0, 1, 2, \dots
\]</span></p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>k! means <code>k factorial</code>, Œª &gt; 0 is the expected value of Y, which also equals the variance of Y.</li>
<li>Larger the mean of Y, larger the variance of Y.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>Poisson distribution is used to model counts.</li>
<li>Number of bike users could be modeled as Poisson distribution with mean value. The mean could vary as a function of the covariates.</li>
</ul>
</section>
<section id="poisson-regression-model" class="level2">
<h2 class="anchored" data-anchor-id="poisson-regression-model">Poisson Regression Model</h2>
<p><span class="math display">\[
\log(\lambda(X_1, \dots, X_p)) = \beta_0 + \beta_1X_1 + \dots + \beta_pX_p
\]</span> or equivalently</p>
<p><span class="math display">\[
\lambda(X_1, \dots, X_p) = e^{\beta_0 + \beta_1X_1 + \dots + \beta_pX_p}
\]</span></p>
<ul>
<li>The log of Œª is linear in predictors.</li>
<li>Œª takes on nonnegative values for all values of covariates.</li>
<li>We use maximum likelihood to estimate parameters.</li>
</ul>
</section>
<section id="comparing-poisson-regression-model-to-the-linear-regression-model" class="level2">
<h2 class="anchored" data-anchor-id="comparing-poisson-regression-model-to-the-linear-regression-model">Comparing Poisson Regression Model to the linear regression model</h2>
<ul>
<li>Interpretation of the coefficients</li>
<li>Mean-variance relationship</li>
<li>Nonnegative fitted values</li>
<li>Please read text material for details.</li>
</ul>
</section>
<section id="generalized-linear-models-in-greater-generality" class="level2">
<h2 class="anchored" data-anchor-id="generalized-linear-models-in-greater-generality">Generalized Linear Models in Greater Generality</h2>
<ul>
<li>Three types of regression models have been discussed: linear, logistic and Poisson. They share some common characteristics:
<ol type="1">
<li>Predictors are used to predict response variable. Conditional on predictors, Y belongs to a certain family of distributions. We make different assumption on the family of distributions that Y belongs to, correspondingly, we have different regression models.</li>
<li>Modeling the mean of Y. Use different <em>link function</em> Œ∑, these regression models could be expressed as below:</li>
</ol></li>
</ul>
<p><span class="math display">\[
\eta(E(Y|X_1, \dots, X_p)) = \beta_0 + \beta_1X_1 + \dots + \beta_pX_p
\]</span></p>
<ul>
<li>All these regression models are examples of <strong>Generalized Linear Model(GLM)</strong></li>
</ul>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<ul>
<li>Classification predicts <em>qualitative</em> responses.</li>
<li>Logistic regression, LDA, QDA, and naive Bayes are common classification methods.</li>
<li>Logistic regression models the <em>probability</em> of class membership using the logistic function.</li>
<li>LDA and QDA assume the predictors follow a Gaussian distribution within each class. LDA assumes a <em>common</em> covariance matrix; QDA does not.</li>
<li>Naive Bayes assumes <em>independence</em> of predictors within each class.</li>
<li>The choice of method depends on the data and the bias-variance trade-off.</li>
<li>ROC curves are useful for evaluating classifier performance across a range of thresholds.</li>
<li>Generalized linear models handle responses from non-normal distributions, Poisson regression model is an example.</li>
</ul>
</section>
<section id="thoughts-and-discussion" class="level2">
<h2 class="anchored" data-anchor-id="thoughts-and-discussion">Thoughts and Discussion ü§î</h2>
<div class="incremental">
<ul class="incremental">
<li>Can you think of real-world scenarios where each classification method (logistic regression, LDA, QDA, naive Bayes) might be most appropriate?</li>
<li>How would you choose the ‚Äúbest‚Äù classification method for a given dataset? What metrics would you consider?</li>
<li>What are the limitations of each method? When might they fail?</li>
<li>How does the bias-variance trade-off play a role in choosing a classification method?</li>
<li>Can we apply the knowledge of mean-variance relationship and fitted values to choose suitable regression model?</li>
</ul>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/qiufei\.github\.io\/web-slide-r");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>üîã<a href="https://posit.co"><img src="https://posit.co/wp-content/themes/Posit/assets/images/posit-logo-2024.svg" class="img-fluid" alt="Posit" width="65"></a></p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 ÈÇ±È£û ¬© 2025
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://beian.miit.gov.cn">
<p>ÊµôICPÂ§á 2024072710Âè∑-1</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33021202002511">
<p>ÊµôÂÖ¨ÁΩëÂÆâÂ§á 33021202002511Âè∑</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:hfutqiufei@163.com">
      <i class="bi bi-envelope-at-fill" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>