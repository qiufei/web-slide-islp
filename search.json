[
  {
    "objectID": "qmd/islp1.html",
    "href": "qmd/islp1.html",
    "title": "",
    "section": "",
    "text": "Welcome to Statistical Learning!\n\n\nThis chapter provides a gentle introduction to the exciting world of statistical learning, a powerful toolkit for understanding data. We will explore the core concepts, see real-world examples, and start our journey toward building predictive models."
  },
  {
    "objectID": "qmd/islp1.html#welcome",
    "href": "qmd/islp1.html#welcome",
    "title": "",
    "section": "",
    "text": "Welcome to Statistical Learning!\n\n\nThis chapter provides a gentle introduction to the exciting world of statistical learning, a powerful toolkit for understanding data. We will explore the core concepts, see real-world examples, and start our journey toward building predictive models."
  },
  {
    "objectID": "qmd/islp1.html#what-is-statistical-learning",
    "href": "qmd/islp1.html#what-is-statistical-learning",
    "title": "",
    "section": "What is Statistical Learning?",
    "text": "What is Statistical Learning?\nStatistical learning refers to a vast set of tools for understanding data. These tools can be broadly classified into two categories:\n\n\n1. Supervised Learning:\n\nBuilding a model to predict or estimate an output based on one or more inputs (also known as predictors, features, or independent variables).\nThink of it like teaching a computer to learn from examples where you provide both the questions (inputs) and the answers (outputs).\nExample: Predicting a house price based on its size, location, and number of bedrooms.\n\n\n2. Unsupervised Learning:\n\nDiscovering relationships and structure in data without a predefined output variable.\nHere, you’re letting the computer explore the data and find patterns on its own.\nExample: Grouping customers into different segments based on their purchasing behavior, without knowing in advance what those segments should be."
  },
  {
    "objectID": "qmd/islp1.html#supervised-vs.-unsupervised-a-visual-analogy",
    "href": "qmd/islp1.html#supervised-vs.-unsupervised-a-visual-analogy",
    "title": "",
    "section": "Supervised vs. Unsupervised: A Visual Analogy",
    "text": "Supervised vs. Unsupervised: A Visual Analogy\n\nImagine you have a basket of fruits.\n\nSupervised Learning: You tell a child, “This is an apple, this is a banana, this is an orange.” Then you show them a new fruit and ask, “What is this?”\nUnsupervised Learning: You give the child the basket and say, “Sort these fruits into groups however you think is best.” The child might group them by color, shape, or size, discovering inherent patterns without being told what to look for."
  },
  {
    "objectID": "qmd/islp1.html#data-mining-machine-learning-and-statistical-learning",
    "href": "qmd/islp1.html#data-mining-machine-learning-and-statistical-learning",
    "title": "",
    "section": "Data Mining, Machine Learning, and Statistical Learning",
    "text": "Data Mining, Machine Learning, and Statistical Learning\nThese terms are often used interchangeably, but there are subtle differences:\n\n\n\n\n\ngraph LR\n    A[Data Mining] --&gt; C(Common Ground)\n    B[Machine Learning] --&gt; C\n    D[Statistical Learning] --&gt; C\n    C --&gt; E[Insights & Predictions]\n\n\n\n\n\n\n\nData Mining: Focuses on discovering patterns and extracting knowledge from large datasets, often using techniques from database management and computer science.\nMachine Learning: Primarily concerned with building algorithms that can learn from and make predictions on data. Emphasizes predictive accuracy and computational efficiency.\nStatistical Learning: A subfield of statistics that emphasizes model interpretability and understanding the uncertainty associated with predictions. Provides a rigorous statistical framework for machine learning."
  },
  {
    "objectID": "qmd/islp1.html#real-world-applications",
    "href": "qmd/islp1.html#real-world-applications",
    "title": "",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nLet’s explore some real-world data sets:\n\nWage Data: Analyzing factors that influence a person’s wage.\nStock Market Data: Predicting stock market movements.\nGene Expression Data: Identifying groups of genes with similar expression patterns.\n\nWe will use these data sets throughout the course to illustrate various statistical learning techniques."
  },
  {
    "objectID": "qmd/islp1.html#wage-data-understanding-income",
    "href": "qmd/islp1.html#wage-data-understanding-income",
    "title": "",
    "section": "Wage Data: Understanding Income",
    "text": "Wage Data: Understanding Income\nWe want to understand how a person’s wage is related to their:\n\nAge\nEducation\nYear (calendar year)\n\n\n\n\n\n\n\nNote\n\n\n\nThe goal is to build a model that can predict a person’s wage based on these factors."
  },
  {
    "objectID": "qmd/islp1.html#wage-data-wage-vs.-age",
    "href": "qmd/islp1.html#wage-data-wage-vs.-age",
    "title": "",
    "section": "Wage Data: Wage vs. Age",
    "text": "Wage Data: Wage vs. Age\n\n\n\nWage as a function of age\n\n\n\n\nLeft Panel: This scatterplot shows individual wages plotted against age. The blue line represents the average wage for a given age.\nTrend: Wage generally increases with age until around 60, then decreases. This suggests a non-linear relationship.\nVariability: There’s significant spread around the average, meaning age alone isn’t a perfect predictor."
  },
  {
    "objectID": "qmd/islp1.html#wage-data-wage-vs.-year-education",
    "href": "qmd/islp1.html#wage-data-wage-vs.-year-education",
    "title": "",
    "section": "Wage Data: Wage vs. Year & Education",
    "text": "Wage Data: Wage vs. Year & Education\n\n\n\nWage as a function of year and education\n\n\n\n\nCenter Panel: Shows wage versus year. There’s a gradual increase in average wage over time (2003-2009).\nRight Panel: Boxplots of wage for different education levels (1 = lowest, 5 = highest). Higher education generally leads to higher wages.\nConclusion: Combining age, year, and education will likely provide the most accurate wage prediction."
  },
  {
    "objectID": "qmd/islp1.html#stock-market-data-predicting-direction",
    "href": "qmd/islp1.html#stock-market-data-predicting-direction",
    "title": "",
    "section": "Stock Market Data: Predicting Direction",
    "text": "Stock Market Data: Predicting Direction\n\nGoal: Predict whether the S&P 500 stock index will increase or decrease on a given day.\nInput: Percentage changes in the index over the previous 5 days.\nOutput: Categorical (qualitative) – either “Up” or “Down”. This is a classification problem."
  },
  {
    "objectID": "qmd/islp1.html#stock-market-data-previous-days-change",
    "href": "qmd/islp1.html#stock-market-data-previous-days-change",
    "title": "",
    "section": "Stock Market Data: Previous Day’s Change",
    "text": "Stock Market Data: Previous Day’s Change\n\n\n\nBoxplots of previous day’s change\n\n\n\n\nLeft Panel: Boxplots show the distribution of the previous day’s percentage change, separated by whether the market went “Up” or “Down” today.\nObservation: The two boxplots are very similar, suggesting that yesterday’s performance is not a strong predictor of today’s direction.\nCenter and Right Panel:The boxplots show the 2 days previous and 3 days previous percentage change, separated by whether the market went “Up” or “Down” today. The two boxplots are very similar."
  },
  {
    "objectID": "qmd/islp1.html#stock-market-data-predicting-with-qda",
    "href": "qmd/islp1.html#stock-market-data-predicting-with-qda",
    "title": "",
    "section": "Stock Market Data: Predicting with QDA",
    "text": "Stock Market Data: Predicting with QDA\n\n\n\nQuadratic Discriminant Analysis\n\n\n\n\nA statistical learning method called quadratic discriminant analysis (QDA) was used to predict market direction.\nResult: The model correctly predicted the direction about 60% of the time. This is better than random guessing (50%), but still far from perfect. It suggests weak trends might exist."
  },
  {
    "objectID": "qmd/islp1.html#gene-expression-data-clustering",
    "href": "qmd/islp1.html#gene-expression-data-clustering",
    "title": "",
    "section": "Gene Expression Data: Clustering",
    "text": "Gene Expression Data: Clustering\n\nGoal: Identify groups (clusters) of cancer cell lines based on their gene expression measurements.\nInput: 6,830 gene expression measurements for each of 64 cancer cell lines.\nOutput: None. This is an unsupervised learning problem (specifically, a clustering problem)."
  },
  {
    "objectID": "qmd/islp1.html#gene-expression-data-principal-components",
    "href": "qmd/islp1.html#gene-expression-data-principal-components",
    "title": "",
    "section": "Gene Expression Data: Principal Components",
    "text": "Gene Expression Data: Principal Components\n\n\n\nPrincipal Components Analysis\n\n\n\n\nChallenge: Visualizing 6,830 dimensions is impossible!\nSolution: Principal Component Analysis (PCA) reduces the data to two dimensions (Z1 and Z2) that capture the most important information.\nLeft Panel: Each point represents a cell line, colored by a suggested cluster. At least four groups seems clear.\nRight Panel: Same plot, but points are colored by the actual cancer type (14 types).\nObservation: Cell lines with the same cancer type tend to cluster together, validating the unsupervised clustering. This means that even though we didn’t tell the algorithm the cancer types, it was able to discover them (to some extent) from the gene expression data."
  },
  {
    "objectID": "qmd/islp1.html#a-brief-history-of-statistical-learning",
    "href": "qmd/islp1.html#a-brief-history-of-statistical-learning",
    "title": "",
    "section": "A Brief History of Statistical Learning",
    "text": "A Brief History of Statistical Learning\n\n\nEarly Beginnings (19th Century): Least squares (linear regression).\nMid-20th Century (1930s-1970s): Linear discriminant analysis, logistic regression, generalized linear models.\nComputational Revolution (1980s onwards): Non-linear methods become feasible (e.g., trees, generalized additive models). Neural Networks and Support Vector Machine were proposed.\nModern Era: Statistical learning emerges as a distinct field, fueled by powerful software (like Python) and increasing data availability."
  },
  {
    "objectID": "qmd/islp1.html#notation",
    "href": "qmd/islp1.html#notation",
    "title": "",
    "section": "Notation",
    "text": "Notation\n\n\nn: Number of observations (data points).\np: Number of variables (features, predictors).\nxij: Value of the jth variable for the ith observation.\nX: A matrix (n x p) representing the data. Think of it as a spreadsheet.\nyi: the ith observation of the variable on which we wish to make predictions\nBold lowercase (e.g., a): A vector of length n.\nNormal lowercase (e.g., a): A scalar (single number) or a vector not of length n.\nBold capitals (e.g., A): A matrix."
  },
  {
    "objectID": "qmd/islp1.html#notation-example-wage-data",
    "href": "qmd/islp1.html#notation-example-wage-data",
    "title": "",
    "section": "Notation: Example (Wage Data)",
    "text": "Notation: Example (Wage Data)\n\n\nn = 3000 (3000 people)\np = 11 (variables like year, age, education, etc.)\nx23 would be the value of the 3rd variable (e.g., education) for the 2nd person.\nX is a 3000 x 11 matrix.\ny1: the first person’s wage."
  },
  {
    "objectID": "qmd/islp1.html#summary",
    "href": "qmd/islp1.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\n\n\nStatistical learning provides tools to understand data, both with and without a specific outcome to predict.\nSupervised learning aims to predict an output, while unsupervised learning explores data structure.\nData mining, machine learning, and statistical learning are related but have different emphases.\nReal-world applications include predicting wages, stock market movements, and clustering gene expression data.\nUnderstanding notation is crucial for following the rest of the course."
  },
  {
    "objectID": "qmd/islp1.html#thoughts-and-discussion",
    "href": "qmd/islp1.html#thoughts-and-discussion",
    "title": "",
    "section": "Thoughts and Discussion",
    "text": "Thoughts and Discussion\n\n\nCan you think of other examples of supervised and unsupervised learning problems in your field of interest?\nWhy is it important to understand the limitations of statistical learning models, even when they achieve good predictive accuracy?\nWhat are the potential ethical implications of using statistical learning models in areas like hiring, loan applications, or criminal justice?\nHow do you imagine the combination of increasing data availability, more powerful hardware, and user-friendly software will further transform the field of statistical learning, making more sophisticated machine learning available to even more researchers?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "我是邱飞，这是我的个人网站，\n用于分享一些数据分析文章，还有个人的记录和资料。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "统计学习导论",
    "section": "",
    "text": "教材采用著名的ISL(Introduction to Statistical Learning)\nhttps://www.statlearning.com/"
  },
  {
    "objectID": "index.html#教材",
    "href": "index.html#教材",
    "title": "统计学习导论",
    "section": "",
    "text": "教材采用著名的ISL(Introduction to Statistical Learning)\nhttps://www.statlearning.com/"
  },
  {
    "objectID": "index.html#ppt",
    "href": "index.html#ppt",
    "title": "统计学习导论",
    "section": "ppt",
    "text": "ppt\n 第一章 \n 第二章 \n 第三章 \n 第四章 \n 第五章 \n 第六章 \n 第七章 \n 第八章 \n 第九章 \n 第十章 \n 第十一章 \n 第十二章 \n 第十三章"
  }
]